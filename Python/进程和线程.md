

# 并发和并行

并发：看起来同时运行的就可以成为并发
并行：真的意义上的同时执行

    PS： 并行肯定算并发
              单核计算机能使进行并发，但不能实现并行

假设单核就是一个核，不算计算机CPU内核

# 单核多通道技术

​        切换CPU分两种情况
​            1.当一个程序遇到IO操作时，操作系统会剥夺程序的CPU的执行权限
​            2.当一个程序长时间占用CPU时，操作系统也会剥夺该程序的CPU执行权限

# 进程理论

## 进程（Process）是什么？

​        是计算机中的程序关于某数据集合上的一次运行活动
​        是系统进行资源分配和调度的基本单位
​        是操作系统结构的基础
​        

        进程是正在运行的程序的实例（an instance of a computer program that is being executed）
        
    程序与进程的区别：
            程序就是一推躺在硬盘上的代码（死的）
            进程表示程序正在运行的过程（是活的）
    
    进程的特点：
        动态性：进程的实质是程序在多道程序系统中的一次执行过程，进程是动态产生，动态消亡的
        并发性：任何进程都可以同其他进程一起并发执行
        独立性：进程是一个能独立运行的基本单位，同时也是系统分配资源和调度的独立单位
        异步性：由于进程间的相互制约，使进程具有执行的间断性，按各自独立的、不可预知的速度向前推进
        结构特征：进程由程序、数据和进程控制块三部分组成
        
        多个不同的进程可以包含相同的程序：一个程序在不同的数据集里就构成不同的进程
        能得到不同的结果，但是执行过程中，程序不能发生改变

## 进程调度

### 先来先服务

​        先来先服务（FCFS）调度算法是一种最简单的调度算法
​        该算法既可用于作业调度，也可用于进程调度
​        FCFS算法比较有利于长作业（进程），而不利于短作业（进程）
​        由此可知，本算法适合于CPU繁忙型作业，而不利于I/O繁忙型的作业（进程）

### 短作业优先算法

​    短作业（进程）优先调度算法（SJ/PF）是指对短作业或短进程优先调度的算法
​    该算法既可用于作业调度，也可用于进程调度，但其对长作业不利
​    不能保证紧迫性作业（进程）被及时处理
​    并且作业的长短只是被估算出来的

### 时间片轮转法+多级反馈队列

时间片轮转(Round Robin，RR)法的基本思路：
        让每个进程在就绪队列中的等待时间与享受服务的时间成比例

    在时间片轮转法中，需要将CPU的处理时间分成固定大小的时间片
    如果一个进程在被调度选中之后用完了系统规定的时间片，但又未完成要求的任务
    则它自行释放自己所占有的CPU而排到就绪队列的末尾，等待下一次调度
    同时，进程调度程序又去调度当前就绪队列中的第一个进程
    
    显然，轮转法只能用来调度分配一些可以抢占的资源
    这些可以抢占的资源可以随时被剥夺，而且可以将它们再分配给别的进程
    CPU是可抢占资源的一种，但打印机等资源是不可抢占的
    由于作业调度是对除了CPU之外的所有系统硬件资源的分配
    其中又包含有不可抢占资源，所以作业调度不使用轮转法
    
    在轮转法中，时间片长度的选取非常重要
    首先，时间片长度的选择会直接影响到系统的开销和响应时间
    如果时间片长度过短，则调度程序抢占处理机的次数增多
    这将使进程上下文切换次数也大大增加，从而加重系统开销
    反过来，如果时间片长度选择过长
    例如，一个时间片能保证就绪队列中所需执行时间最长的进程能执行完毕
    则轮转法变成了先来先服务法
    时间片长度的选择是根据系统对响应时间的要求和就绪队列中所允许最大的进程数来确定的
    
    在轮转法中，加入到就绪队列的进程有3种情况：
        第一种是分给它的时间片用完，但进程还未完成，回到就绪队列的末尾等待下次调度去继续执行
        第二种情况是分给该进程的时间片并未用完
                    只是因为请求I/O或由于进程的互斥与同步关系而被阻塞。当阻塞解除之后再回到就绪队列
        第三种情况就是新创建进程进入就绪队列
        
    如果对这些进程区别对待，给予不同的优先级和时间片
    从直观上看，可以进一步改善系统服务质量和效率
    例如，可把就绪队列按照进程到达就绪队列的类型和进程被阻塞时的阻塞原因分成不同的就绪队列
    每个队列按FCFS原则排列，各队列之间的进程享有不同的优先级，但同一队列内优先级相同
    这样，当一个进程在执行完它的时间片之后、从睡眠中被唤醒、被创建之后，将进入不同的就绪队列

### 多级反馈队列

​    应设置多个就绪队列，并为各个队列赋予不同的优先级
​    第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低
​    该算法赋予各个队列中进程执行时间片的大小也各不相同
​    在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小
​    当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度
​    当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统
​    如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾
​    再同样地按FCFS原则等待调度执行
​    如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，
​    如此当一个长作业(进程)从第一队列依次降到第n队列后，在第n 队列便采取按时间片轮转的方式运行
​    仅当第一队列空闲时，调度程序才调度第二队列中的进程运行
​    仅当第1～(i-1)队列均空时，才会调度第i队列中的进程运行
​    如果处理机正在第i队列中为某进程服务时，又有新进程进入优先权较高的队列中的任何一个队列)
​    则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第i队列的末尾
​    把处理机分配给新到的高优先权进程

    多级反馈队列调度算法则不必事先知道各种进程所需的执行时间，还可以满足各种类型进程的需要
    因而它是目前被公认的一种较好的进程调度算
## 进程运行三状态图

<img src="C:\Users\ghdyx\AppData\Roaming\Typora\typora-user-images\image-20201227150018618.png" alt="image-20201227150018618" style="zoom:67%;" />



<img src="C:\Users\ghdyx\AppData\Roaming\Typora\typora-user-images\image-20201227150203580.png" alt="image-20201227150203580" style="zoom: 60%;" />

## 两对重要概念

### 同步和异步

（描述任务的提交方式）

​        同步：任务提交后，原地等待结果，等待过程中不做任何事（程序表现结果为卡住）
​        异步：任务提交之后不原地等待任务反馈结果，做其他事情
​                  提交结果获取：任务返回结果有一个异步回调机制自动处理

### 阻塞和非阻塞

（描述程序/进程的运行状态）

​        阻塞：阻塞态
​        非阻塞：就绪态和运行态

## 开启进程的两种方式

### 普通方式

```python
from multiprocessing import Process
import time

def task(name):
    print('%s is running' % name)
    time.sleep(3)
    print('%s is over' % name)
'''
windoes操作系统下  创建进程一定要在main内创建
    因为windows下创建进程类似于模块导入的模式
    会从上往下依次执行代码
linux直接将代码拷贝一份
'''
if __name__ == '__main__':
    p1 = Process(target=task, args=('json',))  # 创建对象
    p2 = Process(target=task, args=('egon',))  # 创建对象
    p3 = Process(target=task, args=('tank',))  # 创建对象
    p1.start()  # 开启进程
    p2.start()  # 开启进程
    p3.start()  # 开启进程
    # p1.join() 
    # p2.join()
    # p3.join() # 主进程(main进程)等待子进程运行结束之后再继续执行
    # 上述三步结束时间大概在3秒，进程间相互独立
    print('main is running over')
```

### 类的继承方式(了解)

```python
# 类的继承也可以开启进程
class MyProcess(Process):
    def run(self) -> None:
        print('hello')
        time.sleep(3)
        print('out')

if __name__ == '__main__':
    p = MyProcess()
    p.start()
    print('main')
```

## 进程的一些其他方法

```python
from multiprocessing import Process
from multiprocessing import current_process
import time
import os

# #查看当前进程进程号
def task():
    # print('%s id running' % current_process().pid)
    print('%s id running' % os.getpid())
    # print('%s id running' % os.getppid())
    time.sleep(3)


if __name__ == '__main__':
    P = Process(target=task)
    P.daemon = True  # 设置为P守护进程，必须在start前面
    P.start()
    print('main')
    P.terminate() # 杀死当前进程
    print(P.is_alive()) # p判断当前进程是否存活

# current_process().pid  	查看当前进程进程号
# os.getpid 				查看当前进程进程号
# os.getppid 				查看父进程的pod号
# P.terminate() 			杀死当前进程
# P.is_alive() 				p判断当前进程是否存活
```

## 进程之间的数据隔离

每个进程之间的相互独立是很明显的，数据非常独立，没有相互联系

## 僵尸进程

主进程内部有进程在运行时，主进程结束之后不会立刻释放占用的进程号，为僵尸进程，也叫做进程的凝滞状态，这种状态是为了保留查询子进程的运行状态的时间

父进程等待子进程结束之后，父进程会回收子进程的pid号

## 孤儿进程

子进程结束之前，父进程意外死亡，此时子进程就是孤儿进程，操作系统内部有回收子进程的流程

## 守护进程

某个进程被设置为另外一个进程（一般为子进程所服务的主进程）的守护进程，那么这个进程随着被守护的进程开始和消亡

## 互斥锁

```python
'''
互斥锁：将并发变为串行，保持数据的安全,牺牲效率
           不同进程对同一份数据进行处理时
          1.不要轻易用锁。容易造成死锁现象
          2.仅在处理数据时加上锁
'''
from multiprocessing import Process
from multiprocessing import Lock
import time
import json
import random
def searth_tic(name):
    with open('ticket_num', 'r', encoding='utf-8') as f:
        data_dic = json.load(f)
    print('%s 查询剩余票数为 %s' % (name, data_dic.get('tic_num')))

def buy(name):
    with open('ticket_num', 'r', encoding='utf-8') as f:
        data_dic = json.load(f)
    time.sleep(random.randint(1, 3))

    if data_dic.get('tic_num') > 0:
        data_dic['tic_num'] -= 1
        with open('ticket_num', 'w', encoding='utf-8') as f:
            json.dump(data_dic, f)
        print('%s success' % name)
    else:
        print('%s false' % name)
        
def run(name, mutex):
    searth_tic(name)
    # buy环节加锁处理，抢锁，buy方法运行，释放锁
    mutex.acquire()
    buy(name)
    mutex.release()

if __name__ == '__main__':
    mutex = Lock()
    for name in range(1, 10):
        P = Process(target=run, args=(name, mutex))
        P.start()

```

## 行锁/表锁

操作某一行数据，其他进程不能操作此行

操作某一个表 ，其他进程不能操作此表

## 进程间数据通讯（IPC机制）

IPC（Inter-Process Communication，进程间通信）

```python
# 利用IPC机制，队列解决进程数据通信问题

from multiprocessing import Queue, Process


def producer(q):
    q.put('hi')
    print('hello big baby')

def consumer(q):
    q.get()
    print('get you')

if __name__ == '__main__':
    q = Queue()
    p = Process(target=producer, args=(q,))
    p2 = Process(target=consumer, args=(q,))
    p.start()
    p2.start()
    # data_q = q.get()
    # print(data_q)
```

# 线程理论

## 什么是线程？

进程：资源单位（仅仅是在内u车内空间中开辟一个独立空间）
线程：执行单位（真正的CPU执行的东西，线程指的是代码执行的过程，
			执行代码所需要的资源都找所在的进程索要）

    操作系统比作工厂，进程是车间，线程是流水线
    每一次进程肯定自带一个线程
    同一个进程下的不同线程数据共享

## 为何要有线程？

​	开设进程：1.申请内存  2.拷贝代码（linux）
​	开合线程：在一个进程内开设多个线程，无需申请内存空间，消耗小

## 开启线程的两种方式

### 普通方式

```python
import time
from threading import Thread

def task(name):
    print('%s is running' % name)
    time.sleep(1)
    print('%s is over' % name)
'''
开启线程不需要在main下面执行代码，直接书写
但是我们习惯性还是将启动命令写在main下面
'''
if __name__ == '__main__':
    t = Thread(target=task, args=('alex',))
    t.start()
    print('main')
```

### 类的继承

```python
class MyThead(Thread):
    def __init__(self, name):
        super().__init__()
        self.name = name

    def run(self) -> None:
        print('hello')
        time.sleep(3)
        print('out')

if __name__ == '__main__':
    p = MyThead('alex')
    p.start()
    print('main')
```

## 多个线程共用一个进程的数据

```python
from threading import Thread

money = 100
def task():
    global money
    money = 666
    print(money)

if __name__ == '__main__':
    t = Thread(target=task)
    t.start()
    print(money)

    """
    666
	666
	"""
```

## 线程的join方法

```python
from threading import Thread
import time

def task(name):
    print('%s is running' % name)
    time.sleep(1)
    print('%s is over' % name)

if __name__ == '__main__':
    t = Thread(target=task, args=('alex', ))
    t.start()
    t.join() # 主线程等待子线程结束再执行
    print('main')
```

## 守护线程

```python
import time
from threading import Thread

def task(name):
    print('%s is running' % name)
    time.sleep(1)
    print('%s is over' % name)

if __name__ == '__main__':
    t = Thread(target=task, args=('alex',))
    t.daemon = True
    t.start()
    print('main')

'''
主线程结束之后不会立即结束，
    会等待所有其他非守护线程结束之后才会结束
主线程结束意味着空间回收
'''
```

## 线程的其他方法

```python
from  threading import Thread
# import os
import time

def task():
    print('hello')
    # print('hello world', current_thread().name)  # 获得当前进程的名称

if __name__ == '__main__':
    t = Thread(target=task)
    t.start()
    print('main')

'''  
  print('main',os.getpid()) # 获得进程号
  print('main', active_count()) # 统计活跃的线程数
'''
```

# 多线程的TCP通讯

```python
from socket import *
from threading import Thread
from multiprocessing import Process
"""
服务端
    1.固定IP&PORT
    2.不间断服务
    3.支持并发
"""
buffsize = 1024
server = socket(AF_INET, SOCK_STREAM)
server.bind(('127.0.0.1', 8945,))
server.listen(5)

def server_talk(conn):
    while True:
        # 链接循环
        try:
            data = conn.recv(buffsize)
            if not data:
                break
            print(data.decode('utf-8'))
            conn.send(data.upper())
        except Exception as e:
            print(e)
            break
    conn.close()

while True:
    # 通讯循环
    conn, addr = server.accept()
    t = Thread(target=server_talk, args=(conn, ))
    t.start()
```

# GIL全局解释器锁

在CPython中，GIL是一把互斥锁，用来阻止同一个进程下的多线程的同时执行
		主要是因为CPython中的内存管理（垃圾回收机制）不是线程安全的
						1.应用计数
						2.标记清除
						3.分代回收
同一个进程下的多个线程无法利用多核优势

​	        单任务10S（都有应用场景！！！）
​		单核：四个任务（计算密集型）
​			多进程：额外开销
​			多线程：节省开销
​		多核：四个任务（计算密集型）
​			多进程：10S
​			多线程：40S
​		多核：（IO密集型）
​			多进程：相对浪费资源
​			多线程：相对节省资源

1.GIL不是Python的特点而是CPython解释器的特点
2.GIL保证解释器级别的数据安全
3.阻止同一个进程下的多线程的同时执行
4.针对不同的数据，仍然需要加不同的锁处理
5.解释型语言的通病：同一个进程下的多线程不能利用多核优势

多进程和多线程都有各自优势
我们通常写项目时多进程下开设多线程
这样的话既可以利用多核也可以节省资源消耗

# 死锁现象（了解）

​    两个人拿着对方的钥匙，都被锁住了

# 递归锁(了解)(RLock)

可以连续地被acquire&release，但是只能被第一个人抢到，内部有一个计数器，被acquier()一次就计数加一，release()一次就计数减一

只有在计数为0时，才可以被下一个人抢到

# 信号量（了解）

​	如果将互斥锁比作一个坑位厕所
​	那么信号量就相当于公共厕所

```python
from threading import Thread
from threading import Semaphore
import time
import random


sm = Semaphore(5)  # 锁的个数
def task(name):
    sm.acquire()
    print('%s is get' % name)
    time.sleep(random.randint(1,5))
    sm.release()

if __name__ == '__main__':
    for i in range(20):
        t = Thread(target= task, args=('%s' % i,))
        t.start()
```

# Event事件

一些进程/线程需要等待另外一些进程/线程完毕之后才能完成，类似于发射信号

```python
from threading import Thread
from threading import Event
import time
import random


event = Event()
def light():
    print('红灯亮')
    time.sleep(random.randint(3,5))
    print('绿灯亮了')
    event.set() #告诉wait方法可以继续执行

def car(name):
    print('%s waiting' % name)
    event.wait()  # 等待事件消息
    print('%s run' % name)

if __name__ == '__main__':
    t = Thread(target=light)
    t.start()
    for i in range(20):
        ca = Thread(target=car, args=(i,))
        ca.start()
```

# 池的概念

​	池是用来保证计算机安全的情况下最大限度的利用计算机
​	他降低了程序的效率，但是保证了计算机硬件安全，从而让你的程序可正常运行

## 进程池和线程池（掌握）

​	无论是开设进程也好还是线程也好，都要消耗资源
​	无限开放，计算机硬件不够

## 进程池(回调)

```python
from concurrent.futures import ProcessPoolExecutor
import time
import os


pool1 = ProcessPoolExecutor(5) # 线程池中固定只有5个进程
# 括号内传入数字
'''
池子造出来之后  里面固定存在五个进程
这五个进程不会出现重复创建和销毁的情况

池子的使用，仅仅需要向任务池子中提交任务即可,池子自动服务
'''

def task(n):
    print(n, os.getpid())
    time.sleep(2)
    return n, 'ok'

'''
任务的提交方式：同步/异步
    同步: 提交任务之后原地等待任务返回结果，不做任何事
    异步：不等待，继续执行
        异步反馈结果获取，应该通过回调机制解决
    回调机制：相当于每个异步任务绑定定时炸弹
                一旦任务有结果立即触发

pool1.submit(task, 1)
print('main') # submit是异步提交
'''

def call_back(n):
    print(n.result())

if __name__ == '__main__':
    list_this = []
    for i in range(20):
        # res = pool1.submit(task, i)
        res = pool1.submit(task, i).add_done_callback(call_back) # 添加的回调机制
        # print(res.result()) # 程序由并发变成了串行，res.result()为目标程序的返回结果
        # list_this.append(res)

    # pool1.shutdown()  # 关闭进程池，等待进程池中的所有任务运行完毕
    #
    # for this in list_this:
    #     print(this.result())
```

## 线程池

```python
from concurrent.futures import ThreadPoolExecutor,ProcessPoolExecutor
import time

pool1 = ThreadPoolExecutor(5) # 线程池中固定只有5个线程
# 括号内传入数字
'''
池子造出来之后  里面固定存在五个线程
这五个线程不会出现重复创建和销毁的情况

池子的使用，仅仅需要向任务池子中提交任务即可,池子自动服务
'''

def task(n):
    print(n)
    time.sleep(2)
    return n, 'ok'

'''
任务的提交方式：同步/异步
pool1.submit(task, 1)
print('main') # submit是异步提交
'''

list_this = []
for i in range(20):
    res = pool1.submit(task, i)
    # print(res.result()) # 程序由并发变成了串行，res.result()为目标程序的返回结果
    list_this.append(res)

pool1.shutdown()  # 关闭线程池，等待线程池中的所有任务运行完毕，再往下走

for this in list_this:
    print(this.result())
```

# 协程

单线程下实现并发（多道技术的应用=切换+保存状态），由程序员想象，实际上不存在

​	CPU切换：1.程序遇到IO
​						 2.程序长时间调用

程序员自己在代码成面上完成切换，一旦遇到IO后，完成切换
这样CPU感觉就是程序在一直运行，没有IO
从而提升程序运行效率

## 切换     

​					IO切换-----》提升效率

​					没有IO切---》降低效率

## 保存状态

保存上依次执行的状态，下一次接着上一次操作往后执行
	yield

# gevent模块（了解）

# IO模型介绍

  Stevens在文章中一共比较了五种IO Model：
  \* blocking IO      阻塞IO
  \* nonblocking IO   非阻塞IO
  \* IO multiplexing   IO多路复用
  \* signal driven IO   信号驱动IO
  \* asynchronous IO  异步IO
  由signal driven IO（信号驱动IO）在实际中并不常用，所以主要介绍其余四种IO Model。

  再说一下IO发生时涉及的对象和步骤。对于一个network IO (这里我们以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，该操作会经历两个阶段：

```
#1）等待数据准备 (Waiting for the data to be ready)
#2）将数据从内核拷贝到进程中(Copying the data from the kernel to the process)
```

## 阻塞IO(blocking IO)

　　在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样：

![img](https://images2017.cnblogs.com/blog/827651/201801/827651-20180121220439365-1845551743.png)

　　

当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。

而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。
**所以，blocking IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被block了。**

几乎所有的程序员第一次接触到的网络编程都是从listen()、send()、recv() 等接口开始的，使用这些接口可以很方便的构建服务器/客户机的模型。然而大部分的socket接口都是阻塞型的。如下图

  ps：所谓阻塞型接口是指系统调用（一般是IO接口）不返回调用结果并让当前线程一直阻塞，只有当该系统调用获得结果或者超时出错时才返回。

   ![img](https://images2017.cnblogs.com/blog/827651/201801/827651-20180121220510146-1447219043.png)

实际上，除非特别指定，几乎所有的IO接口 ( 包括socket接口 ) 都是阻塞型的。这给网络编程带来了一个很大的问题，如在调用recv(1024)的同时，线程将被阻塞，在此期间，线程将无法执行任何运算或响应任何的网络请求。

  一个简单的解决方案：

```
#在服务器端使用多线程（或多进程）。多线程（或多进程）的目的是让每个连接都拥有独立的线程（或进程），这样任何一个连接的阻塞都不会影响其他的连接。
```

  该方案的问题是：

```
#开启多进程或都线程的方式，在遇到要同时响应成百上千路的连接请求，则无论多线程还是多进程都会严重占据系统资源，降低系统对外界响应效率，而且线程与进程本身也更容易进入假死状态。
```

  改进方案：   

```
#很多程序员可能会考虑使用“线程池”或“连接池”。“线程池”旨在减少创建和销毁线程的频率，其维持一定合理数量的线程，并让空闲的线程重新承担新的执行任务。“连接池”维持连接的缓存池，尽量重用已有的连接、减少创建和关闭连接的频率。这两种技术都可以很好的降低系统开销，都被广泛应用很多大型系统，如websphere、tomcat和各种数据库等。
```

  改进后方案其实也存在着问题：

```
#“线程池”和“连接池”技术也只是在一定程度上缓解了频繁调用IO接口带来的资源占用。而且，所谓“池”始终有其上限，当请求大大超过上限时，“池”构成的系统对外界的响应并不比没有池的时候效果好多少。所以使用“池”必须考虑其面临的响应规模，并根据响应规模调整“池”的大小。
```

**对应上例中的所面临的可能同时出现的上千甚至上万次的客户端请求，“线程池”或“连接池”或许可以缓解部分压力，但是不能解决所有问题。总之，多线程模型可以方便高效的解决小规模的服务请求，但面对大规模的服务请求，多线程模型也会遇到瓶颈，可以用非阻塞接口来尝试解决这个问题。**

## 非阻塞IO(non-blocking IO)

Linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子：

　　![img](https://images2017.cnblogs.com/blog/827651/201801/827651-20180121220615537-182050804.png)

从图中可以看出，当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是用户就可以在本次到下次再发起read询问的时间间隔内做其他事情，或者直接再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存（这一阶段仍然是阻塞的），然后返回。

也就是说非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个error。进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。重复上面的过程，循环往复的进行recvform系统调用。这个过程通常被称之为轮询。轮询检查内核数据，直到数据准备好，再拷贝数据到进程，进行数据处理。需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态。

**所以，在非阻塞式IO中，用户进程其实是需要不断的主动询问kernel数据准备好了没有。**

**但是非阻塞IO模型绝不被推荐。**

缺点：

```
#1. 循环调用recv()将大幅度推高CPU占用率；这也是我们在代码中留一句time.sleep(2)的原因,否则在低配主机下极容易出现卡机情况
#2. 任务完成的响应延迟增大了，因为每过一段时间才去轮询一次read操作，而任务可能在两次轮询之间的任意时间完成。这会导致整体数据吞吐量的降低。
```

  ***\*此外，在这个方案中recv()更多的是起到检测“操作是否完成”的作用，实际操作系统提供了更为高效的检测“操作是否完成“作用的接口，例如select()多路复用模式，可以一次检测多个连接是否活跃。\****

## 多路复用IO(IO multiplexing)

IO multiplexing这个词可能有点陌生，但是如果我说select/epoll，大概就都能明白了。有些地方也称这种IO方式为**事件驱动IO**(event driven IO)。我们都知道，select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。它的流程如图：

![img](https://images2017.cnblogs.com/blog/827651/201801/827651-20180121220750724-1438537565.png)

当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。
这个图和blocking IO的图其实并没有太大的不同，事实上还更差一些。因为这里需要使用两个系统调用(select和recvfrom)，而blocking IO只调用了一个系统调用(recvfrom)。但是，用select的优势在于它可以同时处理多个connection。

  **强调：**

  **1. 如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。**

  **2. 在多路复用模型中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。**

  **结论: select的优势在于可以处理多个连接，不适用于单个连接** 

```python
from socket import *
import select

s=socket(AF_INET,SOCK_STREAM)
s.setsockopt(SOL_SOCKET,SO_REUSEADDR,1)
s.bind(('127.0.0.1',8081))
s.listen(5)
s.setblocking(False) #设置socket的接口为非阻塞
read_l=[s,]
while True:
    r_l,w_l,x_l=select.select(read_l,[],[])
    print(r_l)
    for ready_obj in r_l:
        if ready_obj == s:
            conn,addr=ready_obj.accept() #此时的ready_obj等于s
            read_l.append(conn)
        else:
            try:
                data=ready_obj.recv(1024) #此时的ready_obj等于conn
                if not data:
                    ready_obj.close()
                    read_l.remove(ready_obj)
                    continue
                ready_obj.send(data.upper())
            except ConnectionResetError:
                ready_obj.close()
                read_l.remove(ready_obj)

#客户端
from socket import *
c=socket(AF_INET,SOCK_STREAM)
c.connect(('127.0.0.1',8081))

while True:
    msg=input('>>: ')
    if not msg:continue
    c.send(msg.encode('utf-8'))
    data=c.recv(1024)
    print(data.decode('utf-8'))
```

 **select监听fd变化的过程分析：**

```
#用户进程创建socket对象，拷贝监听的fd到内核空间，每一个fd会对应一张系统文件表，内核空间的fd响应到数据后，就会发送信号给用户进程数据已到；
#用户进程再发送系统调用，比如（accept）将内核空间的数据copy到用户空间，同时作为接受数据端内核空间的数据清除，这样重新监听时fd再有新的数据又可以响应到了（发送端因为基于TCP协议所以需要收到应答后才会清除）。
```

  **该模型的优点：**

```
#相比其他模型，使用select() 的事件驱动模型只用单线程（进程）执行，占用资源少，不消耗太多 CPU，同时能够为多客户端提供服务。如果试图建立一个简单的事件驱动的服务器程序，这个模型有一定的参考价值。
```

  **该模型的缺点：**

```
#首先select()接口并不是实现“事件驱动”的最好选择。因为当需要探测的句柄值较大时，select()接口本身需要消耗大量时间去轮询各个句柄。#很多操作系统提供了更为高效的接口，如linux提供了epoll，BSD提供了kqueue，Solaris提供了/dev/poll，…。#如果需要实现更高效的服务器程序，类似epoll这样的接口更被推荐。遗憾的是不同的操作系统特供的epoll接口有很大差异，#所以使用类似于epoll的接口实现具有较好跨平台能力的服务器会比较困难。
#其次，该模型将事件探测和事件响应夹杂在一起，一旦事件响应的执行体庞大，则对整个模型是灾难性的。
```

## 异步IO(Asynchronous I/O)

Linux下的asynchronous IO其实用得不多，从内核2.6版本才开始引入。先看一下它的流程：

![img](https://images2017.cnblogs.com/blog/827651/201801/827651-20180121220949521-1279971385.png)

　　用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。

## IO模型比较分析

到目前为止，已经将四个IO Model都介绍完了。现在回过头来回答最初的那几个问题：blocking和non-blocking的区别在哪，synchronous IO和asynchronous IO的区别在哪。
  先回答最简单的这个：blocking vs non-blocking。前面的介绍中其实已经很明确的说明了这两者的区别。调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。

  再说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。Stevens给出的定义（其实是POSIX的定义）是这样子的：
  A synchronous I/O operation causes the requesting process to be blocked until that I/O operationcompletes;
  An asynchronous I/O operation does not cause the requesting process to be blocked; 
  两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，四个IO模型可以分为两大类，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO这一类，而 asynchronous I/O后一类 。

  有人可能会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。

  各个IO Model的比较如图所示：

　　![img](https://images2017.cnblogs.com/blog/827651/201801/827651-20180121221032662-417642110.png)

　　经过上面的介绍，会发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。

# selectors模块

## IO复用

为了解释这个名词，首先来理解下复用这个概念，复用也就是共用的意思，这样理解还是有些抽象，为此，咱们来理解下复用在通信领域的使用，在通信领域中为了充分利用网络连接的物理介质，往往在同一条网络链路上采用时分复用或频分复用的技术使其在同一链路上传输多路信号，到这里我们就基本上理解了复用的含义，即公用某个“介质”来尽可能多的做同一类(性质)的事，那IO复用的“介质”是什么呢？为此我们首先来看看服务器编程的模型，客户端发来的请求服务端会产生一个进程来对其进行服务，每当来一个客户请求就产生一个进程来服务，然而进程不可能无限制的产生，因此为了解决大量客户端访问的问题，引入了IO复用技术，即：一个进程可以同时对多个客户请求进行服务。也就是说IO复用的“介质”是进程(准确的说复用的是select和poll，因为进程也是靠调用select和poll来实现的)，复用一个进程(select和poll)来对多个IO进行服务，虽然客户端发来的IO是并发的但是IO所需的读写数据多数情况下是没有准备好的，因此就可以利用一个函数(select和poll)来监听IO所需的这些数据的状态，一旦IO有数据可以进行读写了，进程就来对这样的IO进行服务。

  

理解完IO复用后，我们在来看下实现IO复用中的三个API(select、poll和epoll)的区别和联系

select，poll，epoll都是IO多路复用的机制，I/O多路复用就是通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知应用程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。三者的原型如下所示：

int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);

int poll(struct pollfd *fds, nfds_t nfds, int timeout);

int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);



 1.select的第一个参数nfds为fdset集合中最大描述符值加1，fdset是一个位数组，其大小限制为__FD_SETSIZE（1024），位数组的每一位代表其对应的描述符是否需要被检查。第二三四参数表示需要关注读、写、错误事件的文件描述符位数组，这些参数既是输入参数也是输出参数，可能会被内核修改用于标示哪些描述符上发生了关注的事件，所以每次调用select前都需要重新初始化fdset。timeout参数为超时时间，该结构会被内核修改，其值为超时剩余的时间。

## select的调用步骤

（1）使用copy_from_user从用户空间拷贝fdset到内核空间

（2）注册回调函数__pollwait

（3）遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll,udp_poll或者datagram_poll）

（4）以tcp_poll为例，其核心实现就是__pollwait，也就是上面注册的回调函数。

（5）__pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll 来说，其等待队列是sk->sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数 据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。

（6）poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。

（7）如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule_timeout是调用select的进程（也就是 current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout 指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。

（8）把fd_set从内核空间拷贝到用户空间。

总结下select的几大缺点：

（1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大

（2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大

（3）select支持的文件描述符数量太小了，默认是1024

 

2．  poll与select不同，通过一个pollfd数组向内核传递需要关注的事件，故没有描述符个数的限制，pollfd中的events字段和revents分别用于标示关注的事件和发生的事件，故pollfd数组只需要被初始化一次。

 poll的实现机制与select类似，其对应内核中的sys_poll，只不过poll向内核传递pollfd数组，然后对pollfd中的每个描述符进行poll，相比处理fdset来说，poll效率更高。poll返回后，需要对pollfd中的每个元素检查其revents值，来得指事件是否发生。

 

3．直到Linux2.6才出现了由内核直接支持的实现方法，那就是epoll，被公认为Linux2.6下性能最好的多路I/O就绪通知方法。epoll可以同时支持水平触发和边缘触发（Edge Triggered，只告诉进程哪些文件描述符刚刚变为就绪状态，它只说一遍，如果我们没有采取行动，那么它将不会再次告知，这种方式称为边缘触发），理论上边缘触发的性能要更高一些，但是代码实现相当复杂。epoll同样只告知那些就绪的文件描述符，而且当我们调用epoll_wait()获得就绪文件描述符时，返回的不是实际的描述符，而是一个代表就绪描述符数量的值，你只需要去epoll指定的一个数组中依次取得相应数量的文件描述符即可，这里也使用了内存映射（mmap）技术，这样便彻底省掉了这些文件描述符在系统调用时复制的开销。另一个本质的改进在于epoll采用基于事件的就绪通知方式。在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。

 

epoll既然是对select和poll的改进，就应该能避免上述的三个缺点。那epoll都是怎么解决的呢？在此之前，我们先看一下epoll 和select和poll的调用接口上的不同，select和poll都只提供了一个函数——select或者poll函数。而epoll提供了三个函 数，epoll_create,epoll_ctl和epoll_wait，epoll_create是创建一个epoll句柄；epoll_ctl是注 册要监听的事件类型；epoll_wait则是等待事件的产生。

　　对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定 EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝 一次。

　　对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在 epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调 函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用 schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。

　　对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子, 在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。

总结：

（1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用 epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在 epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的 时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间，这就是回调机制带来的性能提升。

（2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要 一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内 部定义的等待队列），这也能节省不少的开销。

这三种IO多路复用模型在不同的平台有着不同的支持，而epoll在windows下就不支持，好在我们有selectors模块，帮我们默认选择当前平台下最合适的

```python
#服务端
from socket import *
import selectors

sel=selectors.DefaultSelector()
def accept(server_fileobj,mask):
    conn,addr=server_fileobj.accept()
    sel.register(conn,selectors.EVENT_READ,read)

def read(conn,mask):
    try:
        data=conn.recv(1024)
        if not data:
            print('closing',conn)
            sel.unregister(conn)
            conn.close()
            return
        conn.send(data.upper()+b'_SB')
    except Exception:
        print('closing', conn)
        sel.unregister(conn)
        conn.close()



server_fileobj=socket(AF_INET,SOCK_STREAM)
server_fileobj.setsockopt(SOL_SOCKET,SO_REUSEADDR,1)
server_fileobj.bind(('127.0.0.1',8088))
server_fileobj.listen(5)
server_fileobj.setblocking(False) #设置socket的接口为非阻塞
sel.register(server_fileobj,selectors.EVENT_READ,accept) #相当于网select的读列表里append了一个文件句柄server_fileobj,并且绑定了一个回调函数accept

while True:
    events=sel.select() #检测所有的fileobj，是否有完成wait data的
    for sel_obj,mask in events:
        callback=sel_obj.data #callback=accpet
        callback(sel_obj.fileobj,mask) #accpet(server_fileobj,1)

#客户端
from socket import *
c=socket(AF_INET,SOCK_STREAM)
c.connect(('127.0.0.1',8088))

while True:
    msg=input('>>: ')
    if not msg:continue
    c.send(msg.encode('utf-8'))
    data=c.recv(1024)
    print(data.decode('utf-8'))

基于selectors模块实现聊天
```

